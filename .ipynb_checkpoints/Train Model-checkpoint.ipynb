{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc4bc6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:31:21.920475: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 22:31:22.041075: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 22:31:22.041113: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 22:31:22.041606: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 22:31:22.099956: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 22:31:22.100728: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 22:31:23.057559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb7ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder containing your images\n",
    "dataset_path = \"dataset_v2\"\n",
    "\n",
    "# Get a list of all image files in the folder\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith('.jpg')]  # Update the extension based on your image format\n",
    "\n",
    "# Initialize an empty array to store the images\n",
    "images = []\n",
    "counter = 0\n",
    "\n",
    "# Load and preprocess each image\n",
    "for file_name in image_files:\n",
    "    file_path = os.path.join(dataset_path, file_name)\n",
    "\n",
    "    # Load the image using keras.preprocessing.image.load_img\n",
    "    img = image.load_img(file_path)  # Adjust the target_size based on your requirements\n",
    "\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    # Preprocess the image (adjust as needed)\n",
    "    img_array = img_array.astype(np.float32) / 255\n",
    "\n",
    "    # Flatten the image and add it to the list\n",
    "    images.append(img_array)\n",
    "\n",
    "# Convert the list of images to a numpy array\n",
    "X_train = np.array(images)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "\n",
    "# Reshape the images\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # -1 automatically computes the remaining dimension\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23209bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan, X_train, epochs=1, batch_size=128):\n",
    "    batch_count = X_train.shape[0] // batch_size\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for _ in range(batch_count):\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "            generated_images = generator.predict(noise)\n",
    "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
    "            discriminator.trainable = True\n",
    "            d_loss_real = discriminator.train_on_batch(image_batch, np.ones(batch_size))\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, np.zeros(batch_size))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, np.ones(batch_size))\n",
    "\n",
    "        print(f\"Epoch {e}/{epochs}, D Loss: {d_loss}, G Loss: {g_loss}\")\n",
    "\n",
    "        if (e + 1) % 10 == 0:\n",
    "            plot_generated_images(generator, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf9b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(generator, epoch, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, 100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples, 128, 128, 3)\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow((generated_images[i] * 255).astype(np.uint8), cmap='viridis', interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'gan_generated_image_epoch_{epoch+7000}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32602e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Generator\n",
    "loaded_generator = load_model(\"generator_model.h5\")\n",
    "\n",
    "# Load Discriminator\n",
    "loaded_discriminator = load_model(\"discriminator_model.h5\")\n",
    "\n",
    "# Load GAN\n",
    "loaded_gan = load_model(\"gan_model.h5\")\n",
    "\n",
    "# Compile the loaded models with the same optimizer and loss\n",
    "loaded_generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "loaded_discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "loaded_gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a00c730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Continue training\n",
    "train_gan(loaded_generator, loaded_discriminator, loaded_gan, X_train, epochs=10000, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57123efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_generator.save(\"generator_model.h5\")\n",
    "loaded_discriminator.save(\"discriminator_model.h5\")\n",
    "loaded_gan.save(\"gan_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
